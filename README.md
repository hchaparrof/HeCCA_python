C√≥digo completo del progreso de la herramienta hecca en python, incluye la implementaci√≥n de la herramienta para el calculo del caudal ambiental por la metodolog√≠a del ideam y se preve√© sumarle la metodolog√≠a del anla.

Uso:
En el archivo setup.json cambiar los datos de archivo_base, archivo_apoyo y archivo_enso, por las ubicaciones de los archivos en su computador.
En el archivo setup.json llenar los datos que sean necesarios, en caso de que "existencia_areas" o "existencia_umbrales" sean "false" no importa los valores de "areas" o "umbrales".
"organismo" establece el algoritmo a utilizar, existen 2 metodolog√≠as diferentes: IDEAM o ANLA, y se selecciona como "ideam" y "anla" respectivamente.
"areas" Se refiere a las √°reas de las cuencas de estudio para las dos estaciones, la base y la de apoyo, en caso de que no se tenga cuenca de apoyo no importa el valor y si no se tiene areas se debe poner false en "existencia_areas", se asume que las √°reas estan en m3/s, pero desde que esten en la misma dimensi√≥n no deber√≠a ser importante.
"umbrales" Se refiere a los umbrales morfometricos de la cuenca de estudio en el lugar de estudio, son los umbrales QB y QTQ o caudal de banca llena y caudal de perdida de conectividad, eso se consigue con un estudio hidraulico para la cuenca, si no se tiene estudios hidraulicos se debe poner false en "existencia_umbrales" en ese caso los umbrales seran tomados como los caudales extremos con un periodo de retorno 2.33 para QB y 2 para QTQ.

Una vez las configuraciones estan completas para correr el c√≥digo hay que ejecutar el script de la siguiente manera:
Primero hay que instalar los requerimientos, para lo cual primero hay que asegurarse de tener python en el sistema y ejecutar los siguientes comandos en windows:
pip install virtualenv
python -m virtualenv entorno_hecca 
entorno_hecca\Scripts\activate
pip install -r requirements.txt
y luego ahora si correr el c√≥digo con:
python3 -OO hecca_final.py
 o 
python -OO hecca_final.py
dependiendo de como este configurado su path.
En linux es:
pip install virtualenv
python -m virtualenv entorno_hecca
source entorno_hecca/bin/activate
pip install -r requirements.txt
y luego ahora si correr el c√≥digo con:
python3 -OO hecca_final.py
 o 
python -OO hecca_final.py
# üé® Proyecto de An√°lisis y Procesamiento de Datos Hidrol√≥gicos

‚≠ê **Repositorio Principal**  
Este repositorio contiene c√≥digo y herramientas para el an√°lisis y procesamiento de datos relacionados con eventos hidrol√≥gicos, as√≠ como su comparaci√≥n y validaci√≥n con par√°metros estad√≠sticos y normativos.

---

üìä **Tabla de Contenidos**
1. [Introducci√≥n](#introducci√≥n)
2. [Estructura del Proyecto](#estructura-del-proyecto)
3. [Requisitos](#requisitos)
4. [Instalaci√≥n](#instalaci√≥n)
5. [Uso](#uso)
6. [Contribuciones](#contribuciones)
7. [Autores](#autores)

---

üî¨ **Introducci√≥n**  
Este proyecto facilita el an√°lisis de eventos hidrol√≥gicos, incluyendo:
- Procesamiento y limpieza de datos (archivos CSV).
- Estad√≠sticas sobre caudales y precipitaciones.
- Comparaci√≥n de eventos con indicadores como ENOS (El Ni√±o-Oscilaci√≥n del Sur).
- Generaci√≥n de par√°metros IHA (Indicators of Hydrologic Alteration).

---

üåê **Estructura del Proyecto**  
‚îú‚îÄ‚îÄ docs/                # Documentaci√≥n del proyecto
‚îú‚îÄ‚îÄ IhaEstado.py       # Procesa estados hidrol√≥gicos seg√∫n normas ANLA
‚îú‚îÄ‚îÄ estadistica_ideam.py # C√°lculos estad√≠sticos de datos
‚îú‚îÄ‚îÄ limpieza_datos.py   # Limpieza de datos crudos
‚îú‚îÄ‚îÄ ingreso_datos.py    # Manejo de ingreso de informaci√≥n
‚îú‚îÄ‚îÄ funciones_*         # Funciones auxiliares para diferentes prop√≥sitos
‚îú‚îÄ‚îÄ enso.json           # Datos relacionados con ENOS
‚îú‚îÄ‚îÄ oni_3.csv          # Archivo con informaci√≥n clim√°tica (ONI)
‚îú‚îÄ‚îÄ README.md          # Este archivo
Detalles por archivo
‚Ä¢  IhaEstado.py: Implementa el c√°lculo y la clasificaci√≥n de estados hidrol√≥gicos basado en las normas ANLA, incluyendo pruebas preliminares para garantizar resultados consistentes.
‚Ä¢	Clase IhaEstado:
o	Atributos:
ÔÇß	grupo_1 a grupo_5: Almacenan diferentes par√°metros calculados seg√∫n las m√©tricas de IHA.
ÔÇß	data_cruda: Contiene el DataFrame original proporcionado como entrada.
ÔÇß	data: Almacena los datos procesados y filtrados.
ÔÇß	start_year, end_year: Identifican el rango temporal de los datos.
o	M√©todos:
ÔÇß	calcular_iha: Ejecuta los c√°lculos de los par√°metros IHA, divididos en cinco grupos, utilizando funciones del m√≥dulo iha_parametros.
ÔÇß	unir_grupos: Combina los grupos de datos en un √∫nico DataFrame para an√°lisis conjunto.
ÔÇß	Operadores sobrescritos: __sub__ y __truediv__ para comparar y dividir instancias de IhaEstado.
‚Ä¢  enso.json: Archivo JSON que almacena datos relacionados con eventos de El Ni√±o y La Ni√±a. Este archivo contiene:
‚Ä¢	Una lista de a√±os asociados con eventos de El Ni√±o (ninio).
‚Ä¢	Una lista de a√±os asociados con eventos de La Ni√±a (ninia).
‚Ä¢	Una clave normal que indica valores est√°ndar cuando no se presentan eventos ENOS espec√≠ficos.
‚Ä¢  consistencia.py: Realiza el an√°lisis de consistencia y homogeneidad de datos hidrol√≥gicos. Las principales funciones son:
‚Ä¢	filtrar_datos: Filtra datos seg√∫n un rango general y excepciones para a√±os espec√≠ficos.
‚Ä¢	procesar_archivos_csv: Procesa m√∫ltiples archivos CSV, generando an√°lisis de caudal acumulado, detectando a√±os consistentes y at√≠picos, y generando gr√°ficas.
‚Ä¢	homogeneidad_helmert: Eval√∫a la homogeneidad usando el m√©todo de Helmert.
‚Ä¢	homogeneidad_kendall: Eval√∫a la homogeneidad utilizando el test de Kendall.


‚Ä¢	estadistica_ideam.py: Realiza an√°lisis estad√≠sticos de los datos obtenidos del IDEAM, con √©nfasis en la detecci√≥n de patrones y tendencias en series temporales.
‚Ä¢  comprobacion_ideam.py: Contiene funciones dise√±adas para realizar pruebas estad√≠sticas sobre datos hidrol√≥gicos de referencia y alterados, incluyendo:
‚Ä¢	prueba_si_cumple: Eval√∫a diferencias estad√≠sticas entre series hidrol√≥gicas.
‚Ä¢	cumple: Determina si una serie alterada cumple con par√°metros normativos en comparaci√≥n con una de referencia.
‚Ä¢	Prueba_porc: Calcula porcentajes aprobatorios seg√∫n criterios espec√≠ficos.
‚Ä¢	calibrar_mes: Ajusta par√°metros de un mes para garantizar cumplimiento con condiciones establecidas.
‚Ä¢	
‚Ä¢	limpieza_datos.py: Encargado de limpiar y estructurar los datos crudos provenientes de diferentes fuentes para su posterior an√°lisis.
‚Ä¢	ingreso_datos.py: Automatiza el proceso de ingreso y verificaci√≥n de datos para garantizar la integridad de la informaci√≥n.
‚Ä¢	funciones_anla.py y funciones_ideam.py: Contienen funciones auxiliares espec√≠ficas para manejar c√°lculos, formatos de datos y transformaciones necesarias en las diferentes etapas del proyecto.
‚Ä¢	enso.json: Archivo JSON que almacena datos relacionados con eventos de El Ni√±o y La Ni√±a.
‚Ä¢	oni_3.csv: Archivo CSV que contiene datos clim√°ticos hist√≥ricos relevantes para el an√°lisis.
________________________________________
üîß Requisitos
‚Ä¢	Python 3.8 o superior
‚Ä¢	Bibliotecas listadas en requirements.txt
________________________________________
üîÑ Instalaci√≥n
1.	Clona el repositorio:
$ git clone https://github.com/tuusuario/tu-repo.git
2.	Accede al directorio:
$ cd tu-repo
3.	Instala los requisitos:
$ pip install -r requirements.txt
________________________________________
üîç Uso
Ejecuci√≥n de scripts principales
1.	Limpieza de datos:
$ python limpieza_datos.py
2.	Procesamiento de estados hidrol√≥gicos:
$ python IhaEstado.py
3.	Generaci√≥n de estad√≠sticas:
$ python estadistica_ideam.py
________________________________________
üí° Contribuciones
‚úÖ Las contribuciones son bienvenidas. Por favor, sigue estos pasos:
1.	Haz un fork del repositorio.
2.	Crea una rama para tus cambios:
$ git checkout -b feature/nueva-funcionalidad
3.	Realiza tus cambios y haz un commit:
$ git commit -m "Agrega nueva funcionalidad"
4.	Env√≠a un pull request.
________________________________________
üë§ Autores

